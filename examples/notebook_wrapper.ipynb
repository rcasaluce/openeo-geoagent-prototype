{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# If the notebook runs from repo/examples/\n",
    "repo_root = Path.cwd().resolve().parent\n",
    "\n",
    "# Load .env from repo root\n",
    "load_dotenv(repo_root / \".env\", override=True)\n",
    "\n",
    "# Make src importable\n",
    "sys.path.insert(0, str(repo_root / \"src\"))\n",
    "\n",
    "# Optional but recommended: force absolute KG path too\n",
    "os.environ[\"OPENEO_COLLECTIONS_KG_PATH\"] = str((repo_root / \"data\" / \"collections_kg.json\").resolve())\n",
    "\n",
    "from openeo_geoagent import openeo_llm\n",
    "\n",
    "\n",
    "# üîπ Test AOI: small polygon example\n",
    "aoi_fc = json.dumps({\n",
    "    \"type\": \"Feature\",\n",
    "    \"geometry\": {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [[\n",
    "            [10.0, 45.0],\n",
    "            [10.2, 45.0],\n",
    "            [10.2, 45.2],\n",
    "            [10.0, 45.2],\n",
    "            [10.0, 45.0],\n",
    "        ]]\n",
    "    },\n",
    "    \"properties\": {}\n",
    "})\n",
    "\n",
    "\n",
    "def build_pg(\n",
    "    instruction: str,\n",
    "    default_collection: str = \"SENTINEL2_L2A\",\n",
    "    show_dsl: bool = True,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Convenient wrapper around the tool:\n",
    "    - asks the tool to also return the intermediate DSL (return_dsl=True)\n",
    "    - prints the intermediate DSL if show_dsl=True\n",
    "    - ALWAYS returns a JSON string containing ONLY the process graph,\n",
    "      or an error JSON string ({\"error\": ...}).\n",
    "    \"\"\"\n",
    "    raw = openeo_llm.build_process_graph_from_instruction.invoke({\n",
    "        \"instruction\": instruction,\n",
    "        \"aoi_feature_collection_json\": aoi_fc,\n",
    "        \"default_collection\": default_collection,\n",
    "        \"return_dsl\": show_dsl,\n",
    "    })\n",
    "\n",
    "    # raw is ALWAYS expected to be a JSON string\n",
    "    try:\n",
    "        obj = json.loads(raw)\n",
    "    except Exception:\n",
    "        # Something went wrong inside the tool\n",
    "        print(\"‚ö†Ô∏è Non-JSON output from build_process_graph_from_instruction:\")\n",
    "        print(raw)\n",
    "        return raw\n",
    "\n",
    "    # If the tool returned an error, pass it through unchanged\n",
    "    if isinstance(obj, dict) and \"error\" in obj:\n",
    "        print(\"‚õî Error from build_process_graph_from_instruction:\")\n",
    "        print(json.dumps(obj, indent=2, ensure_ascii=False))\n",
    "        # Return the JSON error string anyway for consistency\n",
    "        return json.dumps(obj, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # Case 1: return_dsl=True ‚Üí payload {\"dsl\": ..., \"process_graph\": ...}\n",
    "    if isinstance(obj, dict) and \"dsl\" in obj and \"process_graph\" in obj:\n",
    "        if show_dsl:\n",
    "            print(\"\\n================= DSLRequest (intermediate) =================\")\n",
    "            print(json.dumps(obj[\"dsl\"], indent=2, ensure_ascii=False))\n",
    "            print(\"=============================================================\\n\")\n",
    "\n",
    "        pg = obj[\"process_graph\"]\n",
    "        return json.dumps(pg, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # Case 2: return_dsl=False ‚Üí the response is directly the process graph\n",
    "    return json.dumps(obj, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def run_job_and_download(\n",
    "    pg_json: str,\n",
    "    output_path: str,\n",
    "    endpoint: str = \"https://openeo.dataspace.copernicus.eu\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs the process graph on an openEO backend and downloads the result\n",
    "    to the specified path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pg_json : str\n",
    "        JSON string returned by build_pg() (may also contain an error payload).\n",
    "    output_path : str\n",
    "        Target file or directory path. If the backend returns multiple assets,\n",
    "        a folder will be created (if needed).\n",
    "    endpoint : str\n",
    "        openEO backend endpoint URL.\n",
    "    \"\"\"\n",
    "    import pathlib\n",
    "\n",
    "    # 1) Check whether the input is a valid process graph or an error payload\n",
    "    try:\n",
    "        pg = json.loads(pg_json)\n",
    "    except Exception:\n",
    "        print(\"pg_json is not valid JSON:\")\n",
    "        print(pg_json)\n",
    "        return\n",
    "\n",
    "    if isinstance(pg, dict) and \"error\" in pg:\n",
    "        print(\"‚õî Error in process graph payload:\")\n",
    "        print(json.dumps(pg, indent=2, ensure_ascii=False))\n",
    "        return\n",
    "\n",
    "    # 2) Connect and execute as a batch job\n",
    "    conn = openeo.connect(endpoint).authenticate_oidc()\n",
    "    job = conn.create_job(pg)\n",
    "\n",
    "    if hasattr(job, \"start_and_wait\"):\n",
    "        job.start_and_wait()\n",
    "    else:\n",
    "        job.start()\n",
    "        print(\"‚ö†Ô∏è This client has no start_and_wait(): job started, but this helper will not wait for completion.\")\n",
    "\n",
    "    # 3) Retrieve results using JobResults\n",
    "    try:\n",
    "        results = job.get_results()  # JobResults\n",
    "    except Exception as e:\n",
    "        print(f\"‚õî get_results() failed: {e}\")\n",
    "        return\n",
    "\n",
    "    out = pathlib.Path(output_path)\n",
    "\n",
    "    # Case 1: single asset ‚Üí download directly as a file\n",
    "    if hasattr(results, \"get_assets\"):\n",
    "        assets = results.get_assets()\n",
    "        if len(assets) == 1 and hasattr(results, \"download_file\"):\n",
    "            try:\n",
    "                results.download_file(str(out))\n",
    "                print(f\"‚úÖ Single result saved to: {out}\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è download_file() failed: {e}\")\n",
    "\n",
    "    # Case 2: multiple assets, or download_file unavailable ‚Üí use a directory\n",
    "    if out.suffix:\n",
    "        out = out.with_suffix(\"\")\n",
    "\n",
    "    out.mkdir(exist_ok=True)\n",
    "\n",
    "    if hasattr(results, \"download_files\"):\n",
    "        try:\n",
    "            results.download_files(str(out))\n",
    "            print(f\"‚úÖ Multiple results saved to: {out}\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è download_files() failed: {e}\")\n",
    "\n",
    "    print(\"‚ö†Ô∏è Unrecognized results format; no files were downloaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c42cc5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= Process Graph (openEO) =================\n",
      "{\n",
      "  \"process_graph\": {\n",
      "    \"load_s2\": {\n",
      "      \"process_id\": \"load_collection\",\n",
      "      \"arguments\": {\n",
      "        \"id\": \"SENTINEL2_L2A\",\n",
      "        \"bands\": [\n",
      "          \"B02\"\n",
      "        ],\n",
      "        \"spatial_extent\": null,\n",
      "        \"temporal_extent\": null\n",
      "      }\n",
      "    },\n",
      "    \"filter_props_s2\": {\n",
      "      \"process_id\": \"filter_properties\",\n",
      "      \"arguments\": {\n",
      "        \"data\": {\n",
      "          \"from_node\": \"load_s2\"\n",
      "        },\n",
      "        \"expression\": {\n",
      "          \"process_graph\": {\n",
      "            \"get_properties\": {\n",
      "              \"process_id\": \"array_element\",\n",
      "              \"arguments\": {\n",
      "                \"data\": {\n",
      "                  \"from_parameter\": \"item\"\n",
      "                },\n",
      "                \"label\": \"properties\"\n",
      "              }\n",
      "            },\n",
      "            \"get_cloud_cover\": {\n",
      "              \"process_id\": \"array_element\",\n",
      "              \"arguments\": {\n",
      "                \"data\": {\n",
      "                  \"from_node\": \"get_properties\"\n",
      "                },\n",
      "                \"label\": \"eo:cloud_cover\"\n",
      "              }\n",
      "            },\n",
      "            \"lte_node\": {\n",
      "              \"process_id\": \"lte\",\n",
      "              \"arguments\": {\n",
      "                \"x\": {\n",
      "                  \"from_node\": \"get_cloud_cover\"\n",
      "                },\n",
      "                \"y\": 50\n",
      "              },\n",
      "              \"result\": true\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"filter_temp_s2\": {\n",
      "      \"process_id\": \"filter_temporal\",\n",
      "      \"arguments\": {\n",
      "        \"data\": {\n",
      "          \"from_node\": \"filter_props_s2\"\n",
      "        },\n",
      "        \"extent\": [\n",
      "          \"2024-08-01\",\n",
      "          \"2024-09-01\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    \"filter_bbox_s2\": {\n",
      "      \"process_id\": \"filter_bbox\",\n",
      "      \"arguments\": {\n",
      "        \"data\": {\n",
      "          \"from_node\": \"filter_temp_s2\"\n",
      "        },\n",
      "        \"west\": 5.07,\n",
      "        \"east\": 5.1,\n",
      "        \"south\": 51.21,\n",
      "        \"north\": 51.23\n",
      "      }\n",
      "    },\n",
      "    \"reduce_s2\": {\n",
      "      \"process_id\": \"reduce_dimension\",\n",
      "      \"arguments\": {\n",
      "        \"data\": {\n",
      "          \"from_node\": \"filter_bbox_s2\"\n",
      "        },\n",
      "        \"reducer\": {\n",
      "          \"process_graph\": {\n",
      "            \"mean_s2\": {\n",
      "              \"process_id\": \"mean\",\n",
      "              \"arguments\": {\n",
      "                \"data\": {\n",
      "                  \"from_parameter\": \"data\"\n",
      "                }\n",
      "              },\n",
      "              \"result\": true\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"dimension\": \"t\"\n",
      "      }\n",
      "    },\n",
      "    \"load_ndvi\": {\n",
      "      \"process_id\": \"load_collection\",\n",
      "      \"arguments\": {\n",
      "        \"id\": \"TERRASCOPE_S2_NDVI_V2\",\n",
      "        \"bands\": [\n",
      "          \"NDVI_10M\"\n",
      "        ],\n",
      "        \"spatial_extent\": null,\n",
      "        \"temporal_extent\": null\n",
      "      }\n",
      "    },\n",
      "    \"filter_temp_ndvi\": {\n",
      "      \"process_id\": \"filter_temporal\",\n",
      "      \"arguments\": {\n",
      "        \"data\": {\n",
      "          \"from_node\": \"load_ndvi\"\n",
      "        },\n",
      "        \"extent\": [\n",
      "          \"2024-08-01\",\n",
      "          \"2024-09-01\"\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    \"filter_bbox_ndvi\": {\n",
      "      \"process_id\": \"filter_bbox\",\n",
      "      \"arguments\": {\n",
      "        \"data\": {\n",
      "          \"from_node\": \"filter_temp_ndvi\"\n",
      "        },\n",
      "        \"west\": 5.07,\n",
      "        \"east\": 5.1,\n",
      "        \"south\": 51.21,\n",
      "        \"north\": 51.23\n",
      "      }\n",
      "    },\n",
      "    \"reduce_ndvi\": {\n",
      "      \"process_id\": \"reduce_dimension\",\n",
      "      \"arguments\": {\n",
      "        \"data\": {\n",
      "          \"from_node\": \"filter_bbox_ndvi\"\n",
      "        },\n",
      "        \"reducer\": {\n",
      "          \"process_graph\": {\n",
      "            \"mean_ndvi\": {\n",
      "              \"process_id\": \"mean\",\n",
      "              \"arguments\": {\n",
      "                \"data\": {\n",
      "                  \"from_parameter\": \"data\"\n",
      "                }\n",
      "              },\n",
      "              \"result\": true\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"dimension\": \"t\"\n",
      "      }\n",
      "    },\n",
      "    \"merge_cubes\": {\n",
      "      \"process_id\": \"merge_cubes\",\n",
      "      \"arguments\": {\n",
      "        \"cube1\": {\n",
      "          \"from_node\": \"reduce_s2\"\n",
      "        },\n",
      "        \"cube2\": {\n",
      "          \"from_node\": \"reduce_ndvi\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_result\": {\n",
      "      \"process_id\": \"save_result\",\n",
      "      \"arguments\": {\n",
      "        \"data\": {\n",
      "          \"from_node\": \"merge_cubes\"\n",
      "        },\n",
      "        \"format\": \"NetCDF\",\n",
      "        \"options\": {}\n",
      "      },\n",
      "      \"result\": true\n",
      "    }\n",
      "  }\n",
      "}\n",
      "=========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instruction =(\"BUILD A PROCESS GRAPH that loads eight datacubes from collection id 'SENTINEL_5P_L2' over spatial_extent {'west':2.146728,'south':49.446978,'east':6.497314,'north':51.651837} and temporal_extent ['2020-01-01','2021-01-01'], with each load_collection using exactly one band in this order: 'AER_AI_340_380', then 'AER_AI_354_388', then 'CO', then 'HCHO', then 'NO2', then 'O3', then 'SO2', then 'CH4', then merge them sequentially with merge_cubes so the first two loads are merged, the result is merged with the third load, and so on until a single cube contains all eight bands, then apply aggregate_temporal_period to that merged cube with period set to 'dekad' and with a reducer process graph that computes mean over the reducer input parameter data (the mean node is the reducer result), and finally save_result the aggregated cube to format 'NetCDF' with empty options and mark save_result as the overall result.\")\n",
    "\n",
    "\n",
    "instruction = ('BUILD A PROCESS GRAPH that loads collection id \"SENTINEL2_L2A\" with bands [\"B02\"], spatial_extent null, temporal_extent null, and a properties filter on \"eo:cloud_cover\" defined as an lte process comparing the per-item value to 50, then applies filter_temporal with extent [\"2024-08-01\",\"2024-09-01\"] and filter_bbox with extent {\"west\":5.07,\"east\":5.1,\"south\":51.21,\"north\":51.23}, then reduces dimension \"t\" using a mean reducer to get a temporal-mean cube; in parallel load collection id \"TERRASCOPE_S2_NDVI_V2\" with bands [\"NDVI_10M\"] and spatial_extent null and temporal_extent null, apply filter_temporal with the same extent and filter_bbox with the same bbox, then reduce dimension \"t\" with the same mean reducer; merge the two reduced cubes with merge_cubes (Sentinel-2 mean as cube1 and NDVI mean as cube2) and finally save_result the merged cube in format \"NetCDF\" with empty options, marking save_result as the only result node.')\n",
    "\n",
    "pg_json = build_pg(\n",
    "    instruction,\n",
    "    default_collection=\"SENTINEL1_GRD\",\n",
    "    show_dsl=True,    # stampa il DSL intermedio (indices + band_math + output_packing=multi_band)\n",
    ")\n",
    "\n",
    "print(\"\\n================= Process Graph (openEO) =================\")\n",
    "print(pg_json)\n",
    "print(\"=========================================================\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d98408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õî Error from build_process_graph_from_instruction:\n",
      "{\n",
      "  \"error\": \"DSL normalization failed\",\n",
      "  \"details\": \"Missing 'temporal' in DSLRequest. The time range must be specified explicitly in the LLM output.\"\n",
      "}\n",
      "\n",
      "================= Process Graph (openEO) =================\n",
      "{\n",
      "  \"error\": \"DSL normalization failed\",\n",
      "  \"details\": \"Missing 'temporal' in DSLRequest. The time range must be specified explicitly in the LLM output.\"\n",
      "}\n",
      "=========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instruction = (\n",
    "    \"Sulla mia AOI con SENTINEL2_L2A dal 2021-01-01 al 2021-12-31 \"\n",
    "    \"calcola un indice personalizzato CUSTOM_INDEX = (NIR - SWIR1) / (NIR + SWIR1) \"\n",
    "    \"come band-math. \"\n",
    "    \"Prima applica un mosaico temporale mensile con media, poi un filtro spaziale \"\n",
    "    \"mediano 3x3 e una media mobile temporale su finestra 3. \"\n",
    "    \"Restituisci mappe mensili con la media mensile dell'indice. \"\n",
    ")\n",
    "\n",
    "pg_json = build_pg(\n",
    "    instruction,\n",
    "    default_collection=\"SENTINEL2_L2A\",\n",
    "    show_dsl=True,    # stampa il DSL intermedio (indices + band_math + output_packing=multi_band)\n",
    ")\n",
    "\n",
    "print(\"\\n================= Process Graph (openEO) =================\")\n",
    "print(pg_json)\n",
    "print(\"=========================================================\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
